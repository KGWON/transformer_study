{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Addictive attention(Bahdanau Attention)\n",
    "- 1.Production encoder hidden state: encoder의 각 time step 마다의 hidden state\n",
    "- 2.Calculating alignment score: decoder의 이전 hidden state와 encoder의 hidden state를 통해 alignment score를 계산\n",
    "- 3.Softmaxing the alignment score: alignment score vector에 softmax 함수를 적용하여 normalized alignment score를 계산\n",
    "- 4.Calculating the **context vector**: normalized alignment score와 encoder의 hidden state를 곱하여(multiply) 계산\n",
    "- 5.Decoding output: context vector와 **이전** decoder output을 concatenate 하여 현재 decoder의 input을 만들고, 이전 decoder hidden state와 함께 인풋하여 new output을 만든다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference\n",
    "- https://blog.floydhub.com/attention-mechanism/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-20T06:55:57.265767Z",
     "start_time": "2019-12-20T06:55:57.244961Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-20T09:18:19.493530Z",
     "start_time": "2019-12-20T09:18:19.485776Z"
    }
   },
   "outputs": [],
   "source": [
    "class EncoderLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, emb_size, hidden_size, n_layers=1, drop_prob=0):\n",
    "        super(EncoderLSTM, self).__init__()\n",
    "        \n",
    "        # Parameters\n",
    "        self.vocab_size = vocab_size\n",
    "        self.emb_size = emb_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        # Layers\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
    "        self.lstm = nn.LSTM(input_size=emb_size, hidden_size=hidden_size, num_layers=n_layers, dropout=drop_prob, batch_first=True)\n",
    "        \n",
    "    def forward(self, inputs, hidden):\n",
    "        # Embed input words\n",
    "        embedded = self.embedding(inputs)                      # embedded: batch x seq_len x emb_size\n",
    "        \n",
    "        # Pass the embedded word vectors into LSTM and return all outputs\n",
    "        output, (last_hidden, last_cell) = self.lstm(embedded) # output: batch x seq_len x hidden_size \n",
    "                                                               # last_hidden: num_layer x batch_size x hidden_size \n",
    "                                                               # last_cell: num_layer  x batch_size x hidden_size\n",
    "        return output, (last_hidden, last_cell)\n",
    "    \n",
    "    def init_hidden(self, batch_size):\n",
    "        return (torch.zeros(self.n_layers, batch_size, self.hidden_size),\n",
    "                 torch.zeros(self.n_layers, batch_size, self.hidden_size))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-20T09:51:40.823578Z",
     "start_time": "2019-12-20T09:51:40.817726Z"
    }
   },
   "outputs": [],
   "source": [
    "class EncoderLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, n_layers=1, drop_prob=0):\n",
    "        super(EncoderLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, n_layers, dropout=drop_prob, batch_first=True)\n",
    "\n",
    "    def forward(self, inputs, hidden):\n",
    "        # Embed input words\n",
    "        embedded = self.embedding(inputs)\n",
    "        # Pass the embedded word vectors into LSTM and return all outputs\n",
    "        output, hidden = self.lstm(embedded, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self, batch_size=1):\n",
    "        return (torch.zeros(self.n_layers, batch_size, self.hidden_size),\n",
    "                torch.zeros(self.n_layers, batch_size, self.hidden_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-20T09:51:42.463023Z",
     "start_time": "2019-12-20T09:51:42.460365Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 2\n",
    "vocab_size = 10\n",
    "emb_size = 5\n",
    "hidden_size = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-20T09:51:32.860916Z",
     "start_time": "2019-12-20T09:51:32.851965Z"
    }
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'vocab_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-192-843539248867>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEncoderLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0memb_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'vocab_size'"
     ]
    }
   ],
   "source": [
    "encoder = EncoderLSTM(vocab_size=vocab_size, emb_size=emb_size, hidden_size=hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-20T09:51:35.431938Z",
     "start_time": "2019-12-20T09:51:35.419527Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'device' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-193-8a1ba8c4aaf6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhiddens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-181-52a9af60a52f>\u001b[0m in \u001b[0;36minit_hidden\u001b[0;34m(self, batch_size)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0minit_hidden\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         return (torch.zeros(self.n_layers, batch_size, self.hidden_size, device=device),\n\u001b[0m\u001b[1;32m     19\u001b[0m                 torch.zeros(self.n_layers, batch_size, self.hidden_size, device=device))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'device' is not defined"
     ]
    }
   ],
   "source": [
    "hiddens = encoder.init_hidden(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-20T09:52:18.036456Z",
     "start_time": "2019-12-20T09:52:18.033361Z"
    }
   },
   "outputs": [],
   "source": [
    "input_size = 2\n",
    "hidden_size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-20T09:52:18.465459Z",
     "start_time": "2019-12-20T09:52:18.460881Z"
    }
   },
   "outputs": [],
   "source": [
    "encoder = EncoderLSTM(input_size, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-20T09:52:18.874021Z",
     "start_time": "2019-12-20T09:52:18.867139Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[0., 0., 0.]]]), tensor([[[0., 0., 0.]]]))"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hiddens = encoder.init_hidden()\n",
    "hiddens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-20T09:52:19.299589Z",
     "start_time": "2019-12-20T09:52:19.293406Z"
    }
   },
   "outputs": [],
   "source": [
    "inputs = torch.tensor([[0, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-20T09:52:20.083698Z",
     "start_time": "2019-12-20T09:52:20.078590Z"
    }
   },
   "outputs": [],
   "source": [
    "encoder_outputs, hiddens = encoder(inputs, hiddens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-20T09:52:21.908342Z",
     "start_time": "2019-12-20T09:52:21.903269Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 3])"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_outputs.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BahdanauDecoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-20T09:45:37.914917Z",
     "start_time": "2019-12-20T09:45:37.907401Z"
    }
   },
   "outputs": [],
   "source": [
    "class BahdanauDecoder(nn.Module):\n",
    "    def __init__(self, emb_size, hidden_size, output_size, n_layers=1, drop_prob=0.1):\n",
    "        super(BahdanauDecoder, self).__init__()\n",
    "        \n",
    "        # Parameters\n",
    "        self.emb_size = emb_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.drop_prob = drop_prob\n",
    "        \n",
    "        # Layers\n",
    "        self.embedding = nn.Embedding(self.output_size, self.emb_size)\n",
    "        \n",
    "        self.fc_hidden = nn.Linear(self.hidden_size, self.hidden_size, bias=False)  # \n",
    "        self.fc_encoder = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\n",
    "        self.weight = nn.Parameter(torch.FloatTensor(1, self.hidden_size))\n",
    "        self.attn_combine = nn.Linear(self.hidden_size*2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.drop_prob)\n",
    "        self.lstm = nn.LSTM(input_size=self.emb_size + self.hidden_size, hidden_size=self.hidden_size, batch_first=True)\n",
    "        self.classifier = nn.Linear(self.hidden_size, self.output_size)\n",
    "        \n",
    "    def forward(self, inputs, hiddens, encoder_outputs):\n",
    "        encoder_outputs = encoder_outputs.squeeze()\n",
    "        \n",
    "        # Embed input words\n",
    "        embedded = self.embedding(inputs)         # embedded: batch x seq_len x embed_size\n",
    "        embedded = embedded.view(1, -1)           # embedded: 1, batch x seq_len x embed_size\n",
    "        embedded = self.dropout(embedded)         # embedded: 1, batch x seq_len x embed_size\n",
    "        \n",
    "        # Calculating alignment scores\n",
    "        dec_fc = self.fc_hidden(hiddens[0])       # dec_fc: num_layers x batch x hidden_size\n",
    "        enc_fc = self.fc_encoder(encoder_outputs) # enc_fc: batch x seq_len x hidden_size\n",
    "        \n",
    "        return dec_fc + enc_fc\n",
    "        \n",
    "#         return dec_fc, enc_fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-20T09:45:38.494768Z",
     "start_time": "2019-12-20T09:45:38.490688Z"
    }
   },
   "outputs": [],
   "source": [
    "decoder = BahdanauDecoder(emb_size, hidden_size, output_size=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-20T09:45:39.091741Z",
     "start_time": "2019-12-20T09:45:39.031035Z"
    }
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (2) must match the size of tensor b (5) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-180-7b690ce2fc13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhiddens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-178-e2c6099809a3>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, inputs, hiddens, encoder_outputs)\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0menc_fc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc_encoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_outputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# enc_fc: batch x seq_len x hidden_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdec_fc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0menc_fc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m#         return dec_fc, enc_fc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (2) must match the size of tensor b (5) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "decoder(inputs, hiddens, encoder_outputs)[1].size()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
